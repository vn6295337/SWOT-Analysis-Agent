from langgraph.graph import StateGraph
from langchain_core.runnables import RunnableLambda
from src.state import AgentState
from src.nodes.researcher import researcher_node
from src.nodes.analyst import analyst_node
from src.nodes.critic import critic_node
from src.nodes.editor import editor_node
from src.utils.conditions import should_continue
from langsmith import traceable

# Create the cyclic workflow
workflow = StateGraph(AgentState)

# Add all nodes to the workflow
workflow.add_node("Researcher", RunnableLambda(researcher_node))
workflow.add_node("Analyst", RunnableLambda(analyst_node))
workflow.add_node("Critic", RunnableLambda(critic_node))
workflow.add_node("Editor", RunnableLambda(editor_node))

# Define the workflow edges
workflow.set_entry_point("Researcher")
workflow.add_edge("Researcher", "Analyst")
workflow.add_edge("Analyst", "Critic")

# Add conditional edges for the self-correcting loop
workflow.add_conditional_edges(
    "Critic", 
    should_continue, 
    {
        "exit": "__end__",
        "retry": "Editor"
    }
)

# Complete the loop: Editor ‚Üí Critic
workflow.add_edge("Editor", "Critic")

# Set the finish point
workflow.set_finish_point("Critic")

# Enhanced configuration for better tracing
workflow.config = {
    "project_name": "AI-strategy-agent-cyclic",
    "tags": ["self-correcting", "quality-loop", "swot-analysis"],
    "metadata": {
        "version": "1.0",
        "environment": "development",
        "workflow_type": "researcher-analyst-critic-editor"
    }
}

# Compile the workflow
app = workflow.compile()

# Wrapped execution with enhanced tracing
@traceable(name="Run - Self-Correcting SWOT Analysis", tags=["cyclic", "quality-control", "demo"], metadata={"purpose": "iterative_improvement"})
def run_self_correcting_workflow(company_name="Tesla"):
    """Execute the complete self-correcting SWOT analysis workflow"""
    
    # Initialize state with default values
    initial_state = {
        "company_name": company_name,
        "raw_data": None,
        "draft_report": None,
        "critique": None,
        "revision_count": 0,
        "messages": [],
        "score": 0
    }
    
    # Execute the workflow
    output = app.invoke(initial_state)
    
    return output

# Main execution
if __name__ == "__main__":
    # Test with Tesla as the default company
    target_company = "Tesla"
    
    print(f"üîç Running Self-Correcting SWOT Analysis for {target_company}...")
    print("üìù This workflow includes: Researcher ‚Üí Analyst ‚Üí Critic ‚Üí Editor (loop)")
    print("üéØ Loop continues until score ‚â• 7 or 3 revisions attempted\n")
    
    # Execute the workflow
    result = run_self_correcting_workflow(target_company)
    
    # Display results (with safe fallbacks)
    print(f"üèÅ Analysis completed for {target_company}!")
    final_score = result.get('score', 'N/A')
    final_revision_count = result.get('revision_count', 0)
    final_critique = result.get('critique', 'No critique available')
    
    print(f"üìä Final Score: {final_score}/10")
    print(f"üîÑ Revision Count: {final_revision_count}")
    print(f"üí¨ Critique: {final_critique}")
    print(f"\nüìÑ Final SWOT Analysis:")
    print(result['draft_report'])
    
    # Summary
    print(f"\n‚úÖ Self-Correcting Workflow Summary:")
    print(f"   - Company: {target_company}")
    print(f"   - Initial Quality: Improved from unknown to {final_score}/10")
    print(f"   - Revisions Made: {final_revision_count}")
    print(f"   - Final Report Length: {len(result['draft_report'])} characters")
    print(f"   - Workflow: Researcher ‚Üí Analyst ‚Üí Critic ‚Üí Editor (loop)")
    print(f"   - Tracing: Enhanced LangSmith traces available")
    
    # Quality assessment
    if isinstance(final_score, (int, float)) and final_score >= 7:
        print(f"   - Quality Assessment: ‚úÖ PASSED ({final_score}/10)")
    else:
        print(f"   - Quality Assessment: ‚ö†Ô∏è  ACCEPTABLE ({final_score} - max revisions reached)")